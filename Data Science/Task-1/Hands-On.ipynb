{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invisible-corps",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "\n",
    "# For numerical computation on nd-arrays\n",
    "import numpy as np\n",
    "\n",
    "# For data analysis and manipulations with dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Data visualization library\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data visualization library built upon matplotlib\n",
    "import seaborn as sns\n",
    " \n",
    "# To ignore warnings related to versions mismatch or updates\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "# Using this, the output of plotting commands is displayed inline within this notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# This class contains methods to perform analysis and find insights\n",
    "# Some generalizations has been done according to all Datasets\n",
    "class Analysis:\n",
    "    \n",
    "    # These class variables have been assigned as per the general behaviour of each dataset\n",
    "    # Can easily be updated for an individual dataset\n",
    "    \n",
    "    # \"Price\" is the target variable for all the datasets, one which has to be predicted\n",
    "    target = \"Price\"\n",
    "    \n",
    "    # This is a list of attributes which are not categorical to further help in analyzing categ features\n",
    "    not_categorical = [\"Area\", \"Price\", \"Location\"]\n",
    "    \n",
    "    # These attributes has strongest correlation with target variable in almost all datasets\n",
    "    strong_corr = [\"Area\", \"No. of Bedrooms\"]\n",
    "    \n",
    "    # On these numeric attributes, outlier removal must be done to gain better insights\n",
    "    remove_outliers = [\"Area\", \"Price\"]\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        self.df = pd.read_csv(name)\n",
    "        self.df_num = self.df.select_dtypes(include = ['float64', 'int64'])\n",
    "        print(f\"Shape - {self.df.shape}\")\n",
    "        \n",
    "        # Remove duplicate rows\n",
    "        print(\"Removed duplicate rows\")\n",
    "        self.df.drop_duplicates(inplace=True)\n",
    "        print(f\"Shape after removing duplicate rows - {self.df.shape}\")\n",
    "        \n",
    "        #Check for missing values\n",
    "        for index, value in self.df.isnull().sum().iteritems():\n",
    "            if value > 0:\n",
    "                print(f\"There are {value} missing values in column - {index}\")\n",
    "        else:\n",
    "            print(\"No missing values in dataset!\")\n",
    "    \n",
    "    def PlotTargetVar(self):\n",
    "        print(\"Distribution of target variable\\n\")\n",
    "        print(\"Skewness: %f\" % self.df[Analysis.target].skew())\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        sns.distplot(self.df[Analysis.target], bins=100, color='r')\n",
    "        \n",
    "    def PlotFeatures(self):\n",
    "        print(\"Distribution of data on each series in the df, resulting in one histogram per column\\n\")\n",
    "        self.df_num.hist(figsize=(20, 20), bins=50, xlabelsize=8, ylabelsize=8)\n",
    "    \n",
    "    def CorrTarget(self):\n",
    "        print(\"Correlation of every attribute with {}\".format(Analysis.target))\n",
    "        price_corr = self.df_num.corr()[Analysis.target][1:]\n",
    "        print(price_corr.sort_values(ascending=False))\n",
    "        #Adding strongly correlated values for plotting regplots\n",
    "        for attr, corr in price_corr[abs(price_corr) > 0.3].sort_values(ascending=False).iteritems():\n",
    "            if attr not in Analysis.strong_corr:\n",
    "                Analysis.strong_corr.append(attr)\n",
    "    \n",
    "    def CorrFeatures(self):\n",
    "        print(\"Analyzing feature to feature relationships\\n\")\n",
    "        plt.figure(figsize=(24, 20))\n",
    "        sns.heatmap(self.df_num.corr(), annot=True, annot_kws={\"size\": 8});\n",
    "        \n",
    "    def CategoricalFeatures(self):\n",
    "        print(\"Lets look at categorical features distribution\\n\")\n",
    "        df_cat = self.df.drop(columns=Analysis.not_categorical)\n",
    "        for col in list(df_cat) :\n",
    "            print(df_cat[col].value_counts())\n",
    "            print('-' * 100)\n",
    "        fig, axes = plt.subplots(round(len(df_cat.columns) / 3), 3, figsize=(6, 15))\n",
    "        for i, ax in enumerate(fig.axes):\n",
    "            if i < len(df_cat.columns):\n",
    "                sns.countplot(x=df_cat.columns[i], data=df_cat, ax=ax);\n",
    "        fig.tight_layout()\n",
    "    \n",
    "    def TargetAnalysisLoc(self):\n",
    "        print(\"Top 5 locations with highest house prices and lowest house prices\\n\")\n",
    "        ltop = self.df.groupby(\"Location\")[Analysis.target].sum().sort_values(ascending=False)[:5]\n",
    "        lbot = self.df.groupby(\"Location\")[Analysis.target].sum().sort_values(ascending=True)[:5]\n",
    "        loc = ltop.append(lbot)\n",
    "        loc.plot.bar(figsize=(30,15))\n",
    "        plt.tick_params(axis='both', labelsize=18)\n",
    "        plt.xticks(rotation=45)\n",
    "    \n",
    "    def StrongCorrRegplot(self):\n",
    "        print(\"Plotting data and linear regression model fit for strongly correlated values with\", Analysis.target)\n",
    "        rows = round(len(list(Analysis.strong_corr)) / 3)\n",
    "        cols = 3\n",
    "        fig, ax = plt.subplots(rows, cols, figsize=(cols*4,rows*3))\n",
    "        for i, ax in enumerate(fig.axes):\n",
    "            if i < len(Analysis.strong_corr):\n",
    "                sns.regplot(x=Analysis.strong_corr[i], y='Price', data=self.df, ax=ax,\n",
    "                                       scatter_kws={'s':6, 'alpha':0.8, 'color':'gray'},\n",
    "                                line_kws={'lw':2, 'color':'black', 'linestyle':'dashed'})\n",
    "    \n",
    "    def OutlierAnalysis(self, columns=[]):\n",
    "        Analysis.remove_outliers.extend(columns)\n",
    "        \n",
    "        # We'll perform outlier analysis on Price and Area using IQR score\n",
    "        for col in Analysis.remove_outliers:\n",
    "            Q1 = self.df[col].quantile(0.25)\n",
    "            Q3 = self.df[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            self.df = self.df[~((self.df[col] < Q1 - 1.5 * IQR) | (self.df[col] > Q3 + 1.5 * IQR))]\n",
    "        print(\"Removed outliers from \", end = '')\n",
    "        for col in Analysis.remove_outliers:\n",
    "            print(col, end = ' ')\n",
    "        print(f\"\\nShape after removing outliers - {self.df.shape}\")\n",
    "            \n",
    "    def CategorialToTarget(self):\n",
    "        print(f\"Relation to {Analysis.target} for all categorical features\")\n",
    "        df_cat = self.df.drop(columns=Analysis.not_categorical)\n",
    "        rows = round(len(list(df_cat)) / 3)\n",
    "        cols = 3\n",
    "        fig, ax = plt.subplots(rows, cols, figsize=(cols*4,rows*3))\n",
    "        for i, ax in enumerate(fig.axes):\n",
    "            if i < len(df_cat.columns):\n",
    "                sns.boxplot(x=list(df_cat)[i], y=Analysis.target, data=self.df, ax = ax)\n",
    "        fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legitimate-cherry",
   "metadata": {},
   "outputs": [],
   "source": [
    "City = Analysis(\"Datasets/?.csv\")\n",
    "\n",
    "# Top 5 rows\n",
    "City.df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "orange-consent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information about dataframe and datatype of each attribute  \n",
    "City.df.info(verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contemporary-colleague",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It gives us all the statistical measures\n",
    "City.df[[\"Price\", \"Area\"]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hazardous-moderator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To gain better insights, let's remove outliers from attributes- price and area\n",
    "# You can also add parameter as a list of attributes for which outlier analysis has to be done\n",
    "# By default, Price and Area as already been added to the list\n",
    "City.OutlierAnalysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatal-relations",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots the distribution of target variable\n",
    "# You can change the target variable using City.target = target_var, by default it's Price\n",
    "City.PlotTargetVar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moral-rental",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's perfrom distribution of data on each feature for better analysis\n",
    "City.PlotFeatures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rational-guyana",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's find columns with strong correlation to target\n",
    "City.CorrTarget()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "happy-murray",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse strongly related features to target variable\n",
    "City.StrongCorrRegplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleared-island",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis of feature to feature relationships using a heatmap\n",
    "City.CorrFeatures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mighty-electricity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at each categorical feature\n",
    "City.CategoricalFeatures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minor-jefferson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also analyze their relationship to target variable\n",
    "City.CategorialToTarget()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elect-feeling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's analyze how house price varies according to locations\n",
    "City.TargetAnalysisLoc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
